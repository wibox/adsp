{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "atqpfO6AuYqD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import tempfile\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "from torchgeo.datamodules import CycloneDataModule\n",
        "from torchgeo.datasets import Sentinel2\n",
        "from torchgeo.trainers import RegressionTask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "0X4j3JAuvD7z"
      },
      "outputs": [],
      "source": [
        "# we set a flag to check to see whether the notebook is currently being run by PyTest, if this is the case then we'll\n",
        "# skip the expensive training.\n",
        "in_tests = \"PYTEST_CURRENT_TEST\" in os.environ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "nMhFnnR6vJQO"
      },
      "outputs": [],
      "source": [
        "# API_KEY generata su https://mlhub.earth/profile, non scade mai, quindi usiamo sempre questa nel caso\n",
        "MLHUB_API_KEY = os.environ.get(\"d8da54d06b97104d4669d0464f6395642bc0509d34f60813f93275b20faf46c4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "tOn4A9fLv9YF"
      },
      "outputs": [],
      "source": [
        "# Questa cella si crea la cartella con i data in /tmp/cyclone_data e li salva lì, però non lo fa, indagherò sul perchè\n",
        "data_dir = os.path.join(tempfile.gettempdir(), \"cyclone_data\")\n",
        "\n",
        "datamodule = CycloneDataModule(root_dir=data_dir, seed=1337, batch_size=64, num_workers=6, api_key=MLHUB_API_KEY, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "9WxQHvREwgoA"
      },
      "outputs": [],
      "source": [
        "# Modo semplice e super clean per definire una regression task\n",
        "task = RegressionTask(\n",
        "    model=\"resnet18\",\n",
        "    pretrained=True,\n",
        "    learning_rate=0.1,\n",
        "    learning_rate_schedule_patience=5,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "mED381C6wh3G"
      },
      "outputs": [],
      "source": [
        "# Questa cella definisce dove salvare la roba del logger e i risultati degli esperimenti, insieme a dove salvare i checkpoint della callback e la metrica per cui\n",
        "# Fare early stopping: la validation_loss\n",
        "experiment_dir = os.path.join(tempfile.gettempdir(), \"cyclone_results\")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor=\"val_loss\", dirpath=experiment_dir, save_top_k=1, save_last=True\n",
        ")\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=10)\n",
        "\n",
        "csv_logger = CSVLogger(save_dir=experiment_dir, name=\"tutorial_logs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPb9Ogmpwq7d",
        "outputId": "c52741d2-d042-4889-82e3-70c97c509dea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "# Qui definisce il trainer, che è solo un modo carino per dire l'oggetto che si occupa di usare le callback, definire tutti i parametri del modello, e sul quale viene chiamata il .fit()\n",
        "trainer = pl.Trainer(\n",
        "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
        "    logger=[csv_logger],\n",
        "    default_root_dir=experiment_dir,\n",
        "    min_epochs=1,\n",
        "    max_epochs=10,\n",
        "    fast_dev_run=in_tests,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "Fvo0QRbLwtif",
        "outputId": "cc035f92-1588-48e6-d101-c596c4892d7f"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Dataset not found or corrupted. You can use download=True to download it",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model\u001b[39m=\u001b[39;49mtask, datamodule\u001b[39m=\u001b[39;49mdatamodule)\n",
            "File \u001b[0;32m~/univenv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:579\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`Trainer.fit()` requires a `LightningModule`, got: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    578\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 579\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    580\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    581\u001b[0m )\n",
            "File \u001b[0;32m~/univenv/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
            "File \u001b[0;32m~/univenv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:621\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    614\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    615\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    616\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    617\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    619\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    620\u001b[0m )\n\u001b[0;32m--> 621\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    623\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    624\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[0;32m~/univenv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:988\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[1;32m    987\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: preparing data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 988\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_connector\u001b[39m.\u001b[39;49mprepare_data()\n\u001b[1;32m    990\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[39m# SET UP TRAINING\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    993\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: setting up strategy environment\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/univenv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:110\u001b[0m, in \u001b[0;36mDataConnector.prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     dm_prepare_data_per_node \u001b[39m=\u001b[39m datamodule\u001b[39m.\u001b[39mprepare_data_per_node\n\u001b[1;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m (dm_prepare_data_per_node \u001b[39mand\u001b[39;00m local_rank_zero) \u001b[39mor\u001b[39;00m (\u001b[39mnot\u001b[39;00m dm_prepare_data_per_node \u001b[39mand\u001b[39;00m global_rank_zero):\n\u001b[0;32m--> 110\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_lightning_datamodule_hook(\u001b[39m\"\u001b[39;49m\u001b[39mprepare_data\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    111\u001b[0m \u001b[39m# handle lightning module prepare data:\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39m# check for prepare_data_per_node before calling lightning_module.prepare_data\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39mif\u001b[39;00m lightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/univenv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1321\u001b[0m, in \u001b[0;36mTrainer._call_lightning_datamodule_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[39mif\u001b[39;00m callable(fn):\n\u001b[1;32m   1320\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningDataModule]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatamodule\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1321\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/univenv/lib/python3.8/site-packages/torchgeo/datamodules/cyclone.py:79\u001b[0m, in \u001b[0;36mCycloneDataModule.prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprepare_data\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39m\"\"\"Initialize the main ``Dataset`` objects for use in :func:`setup`.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[39m    This includes optionally downloading the dataset. This is done once per node,\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[39m    while :func:`setup` is done once per GPU.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     TropicalCycloneWindEstimation(\n\u001b[1;32m     80\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot_dir,\n\u001b[1;32m     81\u001b[0m         split\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     82\u001b[0m         download\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_key \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     83\u001b[0m         api_key\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_key,\n\u001b[1;32m     84\u001b[0m     )\n",
            "File \u001b[0;32m~/univenv/lib/python3.8/site-packages/torchgeo/datasets/cyclone.py:91\u001b[0m, in \u001b[0;36mTropicalCycloneWindEstimation.__init__\u001b[0;34m(self, root, split, transforms, download, api_key, checksum)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download(api_key)\n\u001b[1;32m     90\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_integrity():\n\u001b[0;32m---> 91\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     92\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDataset not found or corrupted. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYou can use download=True to download it\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m     )\n\u001b[1;32m     96\u001b[0m output_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollection_id, split, \u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     97\u001b[0m filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, output_dir, \u001b[39m\"\u001b[39m\u001b[39mcollection.json\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found or corrupted. You can use download=True to download it"
          ]
        }
      ],
      "source": [
        "trainer.fit(model=task, datamodule=datamodule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9rMjqZNwylp"
      },
      "outputs": [],
      "source": [
        "# Da qui in poi è tutta visualizzazione\n",
        "if not in_tests:\n",
        "    train_steps = []\n",
        "    train_rmse = []\n",
        "\n",
        "    val_steps = []\n",
        "    val_rmse = []\n",
        "    with open(\n",
        "        os.path.join(experiment_dir, \"tutorial_logs\", \"version_0\", \"metrics.csv\"), \"r\"\n",
        "    ) as f:\n",
        "        csv_reader = csv.DictReader(f, delimiter=\",\")\n",
        "        for i, row in enumerate(csv_reader):\n",
        "            try:\n",
        "                train_rmse.append(float(row[\"train_RMSE\"]))\n",
        "                train_steps.append(i)\n",
        "            except ValueError:  # Ignore rows where train RMSE is empty\n",
        "                pass\n",
        "\n",
        "            try:\n",
        "                val_rmse.append(float(row[\"val_RMSE\"]))\n",
        "                val_steps.append(i)\n",
        "            except ValueError:  # Ignore rows where val RMSE is empty\n",
        "                pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enR6kwVLyeTg"
      },
      "outputs": [],
      "source": [
        "if not in_tests:\n",
        "    plt.figure()\n",
        "    plt.plot(train_steps, train_rmse, label=\"Train RMSE\")\n",
        "    plt.plot(val_steps, val_rmse, label=\"Validation RMSE\")\n",
        "    plt.legend(fontsize=15)\n",
        "    plt.xlabel(\"Batches\", fontsize=15)\n",
        "    plt.ylabel(\"RMSE\", fontsize=15)\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VHQvBI7y1rM"
      },
      "outputs": [],
      "source": [
        "trainer.test(model=task, datamodule=datamodule)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 ('univenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "4d0ca29b2ba1010d177b6aa64925e13cce7bf98b933b35e8c538e5677c80d140"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
